{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"THIS JUPYTER NOTEBOOK IS USED TO CONVERT THE PREDICTED LABELS FOR EACH TEST IMAGE INTO \\nA BLACK-AND-WHITE IMAGE. THE PREDICTED IMAGES WILL BE SAVED INTO THE FOLDER 'PREDICTIONS' \\nWITH THEIR NUMBER RESPECTIVELY\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"THIS JUPYTER NOTEBOOK IS USED TO CONVERT THE PREDICTED LABELS FOR EACH TEST IMAGE INTO \n",
    "A BLACK-AND-WHITE IMAGE. THE PREDICTED IMAGES WILL BE SAVED INTO THE FOLDER 'PREDICTIONS' \n",
    "WITH THEIR NUMBER RESPECTIVELY\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from utils.helpers import *\n",
    "from cnn_model import CnnModel\n",
    "import tensorflow.keras as keras\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_WEIGHTS = '../models/weightsOrig.h5'\n",
    "PATH_UNET = '../models/unet.h5'\n",
    "PATH_TEST_DATA = '../data/test_set_images/'\n",
    "PATH_PREDICTION_DIR = '../data/predictions/'\n",
    "PATH_SUBMISSION = '../final_submission.csv'\n",
    "TEST_SIZE = 50\n",
    "\n",
    "image_filenames_test = [PATH_TEST_DATA + 'test_' + str(i + 1) + '/' + 'test_' +\n",
    "                        str(i + 1) + '.png' for i in range(TEST_SIZE)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_BW(model, image_filename):\n",
    "    \"\"\"FOR VISUALIZATION\"\"\"\n",
    "\n",
    "    image = load_image(image_filename)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    #print(\"loaded test image after reshape\",image.shape)\n",
    "    \n",
    "    \n",
    "    # PREDICT LABELS\n",
    "    labels = model.predict(image)\n",
    "    #print(\"labelsshape1\",labels.shape)\n",
    "    labels = labels.reshape(-1)\n",
    "    #print(\"labelsshape2\",labels.shape)\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_33 (Conv2D)           (None, 72, 72, 64)        4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)   (None, 72, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 36, 36, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)   (None, 36, 36, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 18, 18, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 20736)             0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               2654336   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 3,028,482\n",
      "Trainable params: 3,028,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#instanciate model\n",
    "cnn = CnnModel()\n",
    "cnn.load_weights(PATH_WEIGHTS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n",
      "Predicting images..\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for i in range(TEST_SIZE):\n",
    "    image_filenames = image_filenames_test[i]\n",
    "    labels.append(predicted_BW(cnn, image_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert array of labels to an image\n",
    "def label_to_img(imgwidth, imgheight, w, h, labels):\n",
    "    array_labels = np.zeros([imgwidth, imgheight])\n",
    "    idx = 0\n",
    "    for i in range(0, imgheight, h):\n",
    "        for j in range(0, imgwidth, w):\n",
    "            if labels[idx] > 0.5:  # bgrd\n",
    "                l = 1\n",
    "            else:\n",
    "                l = 0\n",
    "            array_labels[j:j+w, i:i+h] = l\n",
    "            idx = idx + 1\n",
    "    return array_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(TEST_SIZE):\n",
    "    plt.imsave(PATH_PREDICTION_DIR + 'pred_'+str(i+1),label_to_img(608,608,16,16,labels[i]),cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8432dfc390>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: notebook, that involves predictions path to save all the predicted images!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
